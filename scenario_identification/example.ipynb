{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.base import clone\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = 10 # size of bins to consider\n",
    "\n",
    "# expressions to identify column types\n",
    "num_expr = re.compile(\"infections_(\\d+)_to_(\\d+)\")\n",
    "out_degree_expr = re.compile(\"^out_degree_(\\d+)_to_(\\d+)\")\n",
    "bdry_expr = re.compile(\"boundary_out_degree_(\\d+)_to_(\\d+)\")\n",
    "path_ct_expr = re.compile(\"cnt_*\")\n",
    "avg_ct_expr = re.compile(\"avg_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifies which columns correspond to which bucket sizes\n",
    "# We only use one bucket size - experiments found little difference with increased granularity\n",
    "def is_bucket(str_val, expr, size):\n",
    "    matches = expr.match(str_val)\n",
    "    if not matches:\n",
    "        return False\n",
    "    \n",
    "    lb = int(matches[1])\n",
    "    ub = int(matches[2])\n",
    "    \n",
    "    return ub - lb == size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(data, bin_size, estimator, path_expr, col_set=None, n_iter=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    do 10 train/evaluate splits using the specified data, and set of\n",
    "    columns\n",
    "    \n",
    "    data - the aggregate data where each row is a cascade\n",
    "    bin_size - specifies the subset of binned columns to use (e.g. 5, 10)\n",
    "    estimator - an instantiated SkLearn classifier \n",
    "    path_expr - a regex indicating whether to use avg or count for labeled paths\n",
    "    col_set - a tuple indicating which sets of columns to use\n",
    "    \n",
    "    returns - a list of 10 (accuracy, trained_estimator) tuples\n",
    "    \"\"\"\n",
    "    \n",
    "    inf_cols = data.columns[data.columns.map(lambda x: is_bucket(x, num_expr, bin_size))]\n",
    "    path_cols = data.filter(regex=path_expr).columns\n",
    "    \n",
    "    # get all other columns\n",
    "    out_degree_expr = re.compile(\"^out_degree_(\\d+)_to_(\\d+)\")\n",
    "    path_len_cols = data.filter(regex=\"^path_len_*\").columns\n",
    "    out_degree_cols = data.columns[data.columns.map(lambda x: is_bucket(x, out_degree_expr, 2))]\n",
    "\n",
    "    feature_data = data[inf_cols.union(path_cols).union(path_len_cols).union(out_degree_cols)].copy()\n",
    "\n",
    "    norm_cols = inf_cols.union(out_degree_cols).union(path_len_cols)\n",
    "    norm_sums = data[norm_cols].sum(axis=1).values\n",
    "    \n",
    "    feature_data.loc[norm_sums != 0, norm_cols] = feature_data[norm_cols].divide(norm_sums, axis=0)[norm_sums != 0]\n",
    "    \n",
    "    if col_set:\n",
    "        cols = pd.Index([])\n",
    "        if \"inf_cols\" in col_set:\n",
    "            cols = cols.union(inf_cols)\n",
    "        if \"labeled_path_1\" in col_set:\n",
    "            labeled_path_1_ind = ~data.filter(regex=path_expr).columns.str.contains(\"-\")\n",
    "            cols = cols.union(data.filter(regex=path_expr).columns[labeled_path_1_ind])\n",
    "        if \"labeled_path_2\" in col_set:\n",
    "            labeled_path_2_ind = data.filter(regex=path_expr).columns.str.contains(\"-\")\n",
    "            cols = cols.union(data.filter(regex=path_expr).columns[labeled_path_2_ind])\n",
    "        if \"out_degree\" in col_set:\n",
    "            cols = cols.union(out_degree_cols)\n",
    "        if \"path_len\" in col_set:\n",
    "            cols = cols.union(path_len_cols)\n",
    "        feature_data = feature_data[cols]\n",
    "\n",
    "    runs = []\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feature_data, \n",
    "                                                        data[\"label_scenario\"], shuffle=True, \n",
    "                                                        stratify=data[\"label_scenario\"], test_size=0.25)\n",
    "        estimator.fit(X_train, y_train)\n",
    "        acc = estimator.score(X_test, y_test)\n",
    "        \n",
    "        est_arch = deepcopy(estimator)\n",
    "      \n",
    "        runs.append((acc, est_arch))\n",
    "        #print(f\"Iteration {i}, {acc}\")\n",
    "\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_combos = [\n",
    "    (\"inf_cols\", \"path_len\", \"out_degree\", \"labeled_path_1\", \"labeled_path_2\"), # Epicurve + structure\n",
    "    (\"inf_cols\",) # Epicurve only\n",
    "]\n",
    "\n",
    "# whether to use count or average, determined via exploratory testing\n",
    "lr_path_expr = \"cnt_en_*\" \n",
    "rf_path_expr = \"avg_en_*\"\n",
    "svm_path_expr = \"avg_s_en_*\"\n",
    "\n",
    "\n",
    "lr = make_pipeline(LogisticRegression(max_iter=10000))\n",
    "gr_lr = GridSearchCV(lr, param_grid={\n",
    "            \"logisticregression__C\" : np.arange(0.1, 3.0, 0.05)\n",
    "        }, n_jobs=4, cv=5)\n",
    "\n",
    "cv_rf = GridSearchCV(RandomForestClassifier(), param_grid={\n",
    "    \"max_features\" : [\"sqrt\", \"log2\"] + list(range(1,40)),\n",
    "}, n_jobs=4, cv=5)\n",
    "\n",
    "cv_svm = GridSearchCV(make_pipeline(StandardScaler(), SVC(kernel=\"linear\", probability=True)), param_grid={\n",
    "    \"svc__C\" : [1e-2, 1e-1, 1.0, 1e1],    \n",
    "}, n_jobs=4, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in example data\n",
    "\n",
    "data_file = \"../ml_table/exp5_T70_features.csv\"\n",
    "data = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_lr = train_eval_model(data, 10, gr_lr, re.compile(lr_path_expr), col_set=col_combos[0], n_iter=4)\n",
    "epi_lr = train_eval_model(data, 10, gr_lr, re.compile(lr_path_expr), col_set=col_combos[1], n_iter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_rf = train_eval_model(data, 10, cv_rf, re.compile(rf_path_expr), col_set=col_combos[0], n_iter=4)\n",
    "epi_rf = train_eval_model(data, 10, cv_rf, re.compile(rf_path_expr), col_set=col_combos[0], n_iter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_svm = train_eval_model(data, 10, cv_svm, re.compile(svm_path_expr), col_set=col_combos[0], n_iter=4)\n",
    "epi_svm = train_eval_model(data, 10, cv_svm, re.compile(svm_path_expr), col_set=col_combos[1], n_iter=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
